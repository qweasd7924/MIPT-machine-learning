{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E-commerce ranking task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*by Ilya Zakharkin (2017)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting popularities of each item (id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_popularity = Counter()\n",
    "purchase_popularity = Counter()\n",
    "\n",
    "with open('./coursera_sessions_train.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        views, purchases = line.strip().split(';')\n",
    "        for view in views.split(','):\n",
    "            view_popularity[view] += 1\n",
    "        if purchases != '':\n",
    "            for purchase in purchases.split(','):\n",
    "                purchase_popularity[purchase] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recommend_by_purchase(items, max_count):\n",
    "    return heapq.nlargest(max_count, OrderedDict.fromkeys(items), key=lambda x: purchase_popularity.get(x, 0))\n",
    "\n",
    "def recommend_by_view(items, max_count):\n",
    "    return heapq.nlargest(max_count, OrderedDict.fromkeys(items), key=lambda x: view_popularity.get(x, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the models (sortings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let`s calculate **AverageRecall@1, AveragePrecision@1, AverageRecall@5, AveragePrecision@5** both on **training** and on **test** sets with **views_counts** and **purchases_counts**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_sample_with_model(X, model):\n",
    "#     '''Applies model \"model\" to sample X and returns results of calculating default recommender metrics.\n",
    "    \n",
    "#     '''\n",
    "#     if model == 'views':\n",
    "#         counter = views_counter\n",
    "#     elif model == 'purchases':\n",
    "#         counter = purchases_counter\n",
    "#     else:\n",
    "#         return 'Wrong model parameter. Available are: \"views\", \"purchases\"'\n",
    "    \n",
    "#     metrics = [recall_k, precision_k]\n",
    "#     k_values = [1, 5]\n",
    "    \n",
    "#     metrics_dict = defaultdict(lambda : defaultdict(list))\n",
    "\n",
    "#     for id_view_list, id_purch_list in list(zip(X[0], X[1])):\n",
    "#         view_ids = list(set(filter(lambda x: x != 'nan', str(id_view_list).split(','))))\n",
    "#         purch_ids = list(filter(lambda x: x != 'nan', str(id_purch_list).split(',')))\n",
    "\n",
    "#         pred_ids = sorted(view_ids, key=lambda x: counter[x], reverse=True)\n",
    "\n",
    "#         if len(purch_ids) != 0:\n",
    "#             for metric in metrics:\n",
    "#                 for k in k_values:\n",
    "#                         metrics_dict[metric][k].append(metric(k, pred_ids, purch_ids, len(view_ids)))\n",
    "    \n",
    "#     for metric_key in metrics_dict:\n",
    "#         for k in k_values:\n",
    "#             metrics_dict[metric_key][k] = round(np.mean(metrics_dict[metric_key][k]), 2)\n",
    "    \n",
    "#     return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(recommend, max_count, sessions_file):\n",
    "    with open(sessions_file, 'r') as f:\n",
    "        avg_recall = np.zeros(max_count)\n",
    "        avg_precision = np.zeros(max_count)\n",
    "        sessions_count = 0\n",
    "        for line in f.readlines():\n",
    "            views, purchases = line.strip().split(';')\n",
    "            if purchases != '':\n",
    "                views = views.split(',')\n",
    "                purchases = set(purchases.split(','))\n",
    "                rec = recommend(views, max_count)\n",
    "                rec_hits = np.array(list(map(lambda x: x in purchases, rec)))\n",
    "                hits = np.zeros(max_count)\n",
    "                hits[:len(rec_hits)] = rec_hits\n",
    "                sessions_count += 1\n",
    "                avg_recall +=  np.cumsum(hits) / len(purchases)\n",
    "                avg_precision += np.cumsum(hits) / (np.arange(max_count) + 1)\n",
    "\n",
    "    return pandas.DataFrame({\n",
    "            'k': np.arange(max_count) + 1,\n",
    "            'avg_recall@k': [round(x, 2) for x in avg_recall / sessions_count],\n",
    "            'avg_precision@k': [round(x, 2) for x in avg_precision / sessions_count]\n",
    "    }).set_index('k')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "views_popularity_train = calculate_metrics(recommend_by_view, 5, './coursera_sessions_train.txt')\n",
    "views_popularity_test = calculate_metrics(recommend_by_view, 5, './coursera_sessions_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchases_popularity_train = calculate_metrics(recommend_by_purchase, 5, './coursera_sessions_train.txt')\n",
    "purchases_popularity_test = calculate_metrics(recommend_by_purchase, 5, './coursera_sessions_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_and_print_metrics(filename, df):\n",
    "    with open(filename, 'w') as file:\n",
    "        fmt_string = '{0} {1} {2} {3}'\n",
    "        file.write(fmt_string.format(round(df['avg_recall@k'].values[0], 2), round(df['avg_precision@k'].values[0], 2), \n",
    "                   round(df['avg_recall@k'].values[4], 2), round(df['avg_precision@k'].values[4], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_and_print_metrics('./views_popularity_train.txt', views_popularity_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_and_print_metrics('./views_popularity_test.txt', views_popularity_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_and_print_metrics('./purchases_popularity_train.txt', purchases_popularity_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_and_print_metrics('./purchases_popularity_test.txt', purchases_popularity_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
